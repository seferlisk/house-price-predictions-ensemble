{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### In house price prediction, our primary evaluation metric is RMSLE (Root Mean Squared Logarithmic Error). It is calculated by taking the standard RMSE on the natural logarithm of both the predicted and actual values.\n",
    "    - Interpretation: Penalizes relative errors. It considers the percentage difference. A $10k error on a $100k home is penalized similarly to a $100k error on a $1M home.\n",
    "    - Outlier sensitivity: Low. High-priced outliers (e.g., Mansions) do not explode the error metric.\n",
    "    - Target distribution: Ideal for highly right-skewed targets like home prices.\n",
    "    - Directional Bias: Slightly penalizes under-predictions more than over-predictions.\n",
    "Since a buyer's perception of \"overpaying\" is usually relative to the total value of the home, RMSLE perfectly aligns the model's objective with human intuition.\n",
    "\n",
    "####  In contrast, RMSE and MAE:\n",
    "        - Penalize absolute errors.\n",
    "        - Have an outlier sensitivity that is very high (RMSE) or Moderate (MAE).\n",
    "        - Give a symmetric penalty."
   ],
   "id": "9c25b5ec3f60b93f"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-30T14:10:19.508095Z",
     "start_time": "2026-01-30T14:10:17.674917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the Dataset\n",
    "train_path = \"datasets/train.csv\"\n",
    "test_path = \"datasets/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Drop Id from features\n",
    "train_df = train_df.drop('Id', axis=1)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# METRIC JUSTIFICATION: RMSLE vs RMSE Example\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- RMSLE vs RMSE Demonstration ---\")\n",
    "from sklearn.metrics import root_mean_squared_error, root_mean_squared_log_error\n",
    "\n",
    "# Hypothetical Scenario: $10k error on a Cheap home vs an Expensive home\n",
    "actuals = [100_000, 1_000_000]\n",
    "predictions = [110_000, 1_010_000] # $10k error for both\n",
    "\n",
    "rmse = root_mean_squared_error(actuals, predictions)\n",
    "rmsle = root_mean_squared_log_error(actuals, predictions)\n",
    "\n",
    "print(f\"Absolute RMSE for both combined: ${rmse:.2f}\")\n",
    "print(f\"RMSLE (Relative error): {rmsle:.4f}\")\n",
    "print(\"RMSLE naturally normalizes the errors across huge price differences.\\n\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# DATA OVERVIEW & BASELINE REPORT\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- Dataset Overview ---\")\n",
    "print(f\"Shape (Rows, Columns): {train_df.shape}\\n\")\n",
    "\n",
    "# Target Summary\n",
    "target = train_df['SalePrice']\n",
    "print(\"--- Target (SalePrice) Summary ---\")\n",
    "print(f\"Mean:   ${target.mean():,.0f}\")\n",
    "print(f\"Median: ${target.median():,.0f}\")\n",
    "print(f\"Skew:   {target.skew():.2f}\")\n",
    "print()\n",
    "\n",
    "# Feature Typology\n",
    "# Exclude the target from the feature count\n",
    "features = train_df.drop('SalePrice', axis=1)\n",
    "num_features = features.select_dtypes(include=[np.number]).columns\n",
    "cat_features = features.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "print(\"--- Feature Types ---\")\n",
    "print(f\"Numeric features:     {len(num_features)}\")\n",
    "print(f\"Categorical features: {len(cat_features)}\")\n",
    "print()\n",
    "\n",
    "# Missing Values Table\n",
    "print(\"--- Top 10 Missing Features ---\")\n",
    "missing_counts = features.isnull().sum()\n",
    "missing_pct = (missing_counts / len(features)) * 100\n",
    "\n",
    "# Create a DataFrame for easy viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "\n",
    "# Sort and get top 10\n",
    "top_missing = missing_df[missing_df['Missing Count'] > 0].sort_values(by='Missing Count', ascending=False).head(10)\n",
    "\n",
    "# Format the percentage for display\n",
    "top_missing['Percentage'] = top_missing['Percentage'].map('{:.1f}%'.format)\n",
    "\n",
    "print(top_missing)"
   ],
   "id": "7ad0b81661200ce8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RMSLE vs RMSE Demonstration ---\n",
      "Absolute RMSE for both combined: $10000.00\n",
      "RMSLE (Relative error): 0.0678\n",
      "RMSLE naturally normalizes the errors across huge price differences.\n",
      "\n",
      "--- Dataset Overview ---\n",
      "Shape (Rows, Columns): (1460, 80)\n",
      "\n",
      "--- Target (SalePrice) Summary ---\n",
      "Mean:   $180,921\n",
      "Median: $163,000\n",
      "Skew:   1.88\n",
      "\n",
      "--- Feature Types ---\n",
      "Numeric features:     36\n",
      "Categorical features: 43\n",
      "\n",
      "--- Top 10 Missing Features ---\n",
      "              Missing Count Percentage\n",
      "PoolQC                 1453      99.5%\n",
      "MiscFeature            1406      96.3%\n",
      "Alley                  1369      93.8%\n",
      "Fence                  1179      80.8%\n",
      "MasVnrType              872      59.7%\n",
      "FireplaceQu             690      47.3%\n",
      "LotFrontage             259      17.7%\n",
      "GarageType               81       5.5%\n",
      "GarageYrBlt              81       5.5%\n",
      "GarageFinish             81       5.5%\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### We notice that the dataset is right (or positively) skewed.",
   "id": "b4175bb64888682"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T14:10:19.740875Z",
     "start_time": "2026-01-30T14:10:19.511092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate Target and Features\n",
    "y = np.log1p(train_df['SalePrice']) # Log transform target for RMSLE optimization\n",
    "X = train_df.drop('SalePrice', axis=1)\n",
    "X_test_final = test_df.copy()\n",
    "\n",
    "# Define Feature Groups\n",
    "# We manually separate them to apply specific preprocessing\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CUSTOM IMPUTATION STRATEGY\n",
    "# ---------------------------------------------------------\n",
    "# Many features in this dataset have \"Meaningful Missingness\"\n",
    "# e.g., NaN in 'PoolQC' means \"No Pool\", not missing data.\n",
    "\n",
    "none_cols = [\n",
    "    'Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "    'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType'\n",
    "]\n",
    "\n",
    "# For these, we fill NaN with \"None\"\n",
    "for col in none_cols:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].fillna('None')\n",
    "        X_test_final[col] = X_test_final[col].fillna('None')\n",
    "\n",
    "# For GarageYrBlt, if missing, it means no garage. Fill with 0.\n",
    "X['GarageYrBlt'] = X['GarageYrBlt'].fillna(0)\n",
    "X_test_final['GarageYrBlt'] = X_test_final['GarageYrBlt'].fillna(0)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PREPROCESSING PIPELINE\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Numeric Transformer: Impute median for remaining missing (e.g., LotFrontage)\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Categorical Transformer:\n",
    "# 1. Impute 'most_frequent' for true missing values (like Electrical)\n",
    "# 2. OneHotEncode (handle_unknown='ignore' is crucial for new categories in test)\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # sparse_output=False returns a dense array/dataframe\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False # Keeps column names clean\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit/Transform Data\n",
    "# We fit only on training data to avoid data leakage\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_test_processed = preprocessor.transform(X_test_final)\n",
    "\n",
    "print(\"--- Preprocessing Complete ---\")\n",
    "print(f\"Original Feature Count: {X.shape[1]}\")\n",
    "print(f\"Processed Feature Count: {X_processed.shape[1]} (due to One-Hot Encoding)\")\n",
    "print(f\"Target Distribution: Mean={y.mean():.2f}, Std={y.std():.2f} (Log Scale)\")"
   ],
   "id": "b66d079dbe6c299a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing Complete ---\n",
      "Original Feature Count: 79\n",
      "Processed Feature Count: 302 (due to One-Hot Encoding)\n",
      "Target Distribution: Mean=12.02, Std=0.40 (Log Scale)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T14:10:19.751840Z",
     "start_time": "2026-01-30T14:10:19.740875Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "#### In the columns that had \"Meaningful Missingness\", we filled NaN values with 'None'. For the column \"GarageYrBlt\" if a value is missing, it means no garage. So, we filled with 0.\n",
    "    Our models will understand these are features and not errors.\n",
    " To prevent leakage, the preprocessor is fit only on the training set. The test set is transformed using the training set's statistics (medians/modes).\n",
    "\n",
    "### We will evaluate two baseline models using K-Fold Cross-Validation:\n",
    "    Dummy Regressor: Predicts the mean of the training targets for every house. This tells us the \"zero-effort\" error rate.\n",
    "    Linear Regression: A simple linear model to see how much improvement we get just by using the features linearly.\n",
    "\n",
    "\n",
    "\n",
    "Note: Since we already log-transformed the target (y = np.log1p(SalePrice)), calculating RMSE on y is mathematically equivalent to calculating RMSLE on the original prices.\n",
    "\n"
   ],
   "id": "d72c2ef879734401"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T14:30:53.652970Z",
     "start_time": "2026-01-30T14:30:53.192893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. Setup Cross-Validation Strategy\n",
    "# We use KFold with random_state=0 for reproducibility\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "def report_rmsle(model, X, y, name):\n",
    "    # We use 'neg_root_mean_squared_error' because scikit-learn metrics represent 'scores' (higher is better).\n",
    "    # RMSE is an error (lower is better), so sklearn returns negative RMSE.\n",
    "    # We negate it back to get positive RMSE (which corresponds to RMSLE here).\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_root_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "    rmse_scores = -scores\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSLE: {rmse_scores.mean():.4f} ± {rmse_scores.std():.4f}\")\n",
    "    return rmse_scores.mean()\n",
    "\n",
    "print(\"--- Baseline Evaluation (RMSLE) ---\")\n",
    "\n",
    "# 2. Dummy Regressor (Naive Baseline)\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "dummy_score = report_rmsle(dummy, X_processed, y, \"Dummy Regressor (Mean)\")\n",
    "\n",
    "# 3. Linear Regression (Simple Baseline)\n",
    "# OLS without regularization can sometimes overfit if features are collinear,\n",
    "# but it's a good 'next step' baseline.\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg_score = report_rmsle(lin_reg, X_processed, y, \"Linear Regression\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (dummy_score - lin_reg_score) / dummy_score * 100\n",
    "print(f\"\\nImprovement over Dummy: {improvement:.1f}%\")"
   ],
   "id": "a838d95d0702c65a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Evaluation (RMSLE) ---\n",
      "Dummy Regressor (Mean):\n",
      "  RMSLE: 0.3993 ± 0.0244\n",
      "Linear Regression:\n",
      "  RMSLE: 0.1602 ± 0.0480\n",
      "\n",
      "Improvement over Dummy: 59.9%\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Dummy Regressor:  scores around 0.39. This means if you just guess the average price, you are off by ~40% (log-scale roughly translates to percentage error for small values).\n",
    "#### Linear Regression: drops significantly, around 0.16. This confirms the features have strong predictive power."
   ],
   "id": "8239b4a2c710e3f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a5484eb39b1090a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### details",
   "id": "c66b3d028c3f4d8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8df21d2afbc5c81b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
